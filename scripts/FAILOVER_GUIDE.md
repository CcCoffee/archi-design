# Redis Cluster 故障恢复测试指南

## 概述

`failover-test.sh` 脚本用于测试 Redis Cluster 在各种故障场景下的表现，验证集群的高可用性和数据恢复能力。

## 前置条件

- Redis Cluster 已正常运行
- 所有节点状态正常（6 个节点，3 主 3 从）
- 有足够的权限停止和启动 Redis 进程

## 快速开始

```bash
# 运行所有故障测试
./scripts/failover-test.sh all

# 查看帮助
./scripts/failover-test.sh help
```

## 灾难场景分类

| 级别 | 场景 | 影响范围 | 恢复时间 | 测试命令 |
|-----|------|---------|---------|---------|
| P1 | 单节点故障 | 1个节点 | 自动恢复（秒级） | `slave-down`, `master-down` |
| P2 | 网络分区 | 部分节点 | 自动恢复（分钟级） | `network-split`, `multi-failure` |
| P3 | 数据中心故障 | 整个数据中心 | 手动切换（分钟级） | `datacenter-failure` |
| P4 | 灾难恢复 | 全部 | 从备份恢复（小时级） | `disaster-recovery` |

## 测试类型

| 测试类型 | 命令 | 说明 | 灾难级别 |
|---------|------|------|---------|
| 全部测试 | `./failover-test.sh all` | 依次运行所有故障测试 | P1-P4 |
| 从节点故障 | `./failover-test.sh slave-down` | 测试从节点故障场景 | P1 |
| 主节点故障 | `./failover-test.sh master-down` | 测试主节点故障和自动故障转移 | P1 |
| 网络分区 | `./failover-test.sh network-split` | 模拟网络分区场景 | P2 |
| 多节点故障 | `./failover-test.sh multi-failure` | 测试多个节点同时故障 | P2 |
| 数据恢复 | `./failover-test.sh recovery` | 测试持久化和数据恢复能力 | P2 |
| 数据中心故障 | `./failover-test.sh p3` | 测试整个数据中心不可用 | P3 |
| 灾难恢复 | `./failover-test.sh p4` | 测试从备份恢复数据 | P4 |

## 测试详情

### 1. 从节点故障测试 (`slave-down`) - P1

**测试目的**: 验证从节点故障时集群的可用性

**测试流程**:
1. 写入 30 条测试数据
2. 停止一个从节点
3. 验证集群读写功能正常
4. 验证数据完整性
5. 恢复从节点
6. 检查复制状态

**预期结果**:
- 集群状态保持 `ok`
- 读写操作正常
- 数据完整性 100%
- 从节点恢复后复制状态为 `up`

**示例输出**:
```
========================================
  从节点故障测试
========================================

ℹ 测试场景: 从节点 7001 故障
ℹ 预期结果: 集群继续正常服务

✓ 已写入 30/30 条数据
✓ 节点 7001 已停止
✓ 写入测试成功
✓ 读取测试成功
✓ 数据完整性验证通过 (30/30)
✓ 节点 7001 已启动
ℹ 从节点 7001 复制状态: up
```

---

### 2. 主节点故障测试 (`master-down`)

**测试目的**: 验证主节点故障时的自动故障转移

**测试流程**:
1. 写入 50 条测试数据
2. 停止一个主节点
3. 等待约 10 秒（故障转移时间）
4. 验证从节点已提升为主节点
5. 验证数据完整性
6. 恢复原主节点
7. 验证原主节点变为从节点

**预期结果**:
- 从节点自动提升为主节点
- 数据完整性 100%
- 原主节点恢复后角色变为 `slave`

**示例输出**:
```
========================================
  主节点故障测试
========================================

ℹ 测试场景: 主节点 7004 故障
ℹ 预期结果: 从节点 7003 自动提升为主节点

✓ 已写入 50/50 条数据
ℹ 故障前状态:
  主节点: 7004 (ID: 1d9513fd...)
  从节点: 7003

✓ 节点 7004 已停止
ℹ 等待故障转移（约 10 秒）...
✓ 故障转移成功: 从节点 7003 已提升为主节点
✓ 数据完整性验证通过 (50/50)
✓ 节点 7004 已启动
ℹ 原主节点 7004 恢复后角色: slave
```

---

### 3. 多节点故障测试 (`multi-failure`)

**测试目的**: 验证多个节点同时故障时集群的表现

**测试流程**:
1. 写入 30 条测试数据
2. 停止一个从节点
3. 验证集群仍可写入
4. 恢复故障节点
5. 验证数据完整性

**预期结果**:
- 集群状态保持 `ok`
- 写入操作正常
- 数据完整性 100%

---

### 4. 数据恢复测试 (`recovery`)

**测试目的**: 验证持久化机制和数据恢复能力

**测试流程**:
1. 写入 100 条测试数据
2. 触发 RDB 快照（BGSAVE）
3. 检查 RDB 文件
4. 检查 AOF 文件
5. 验证数据完整性

**预期结果**:
- 所有节点都有 RDB 文件
- 所有节点都有 AOF 文件
- 数据完整性 100%

**示例输出**:
```
========================================
  数据恢复测试
========================================

✓ 已写入 100/100 条数据
ℹ 触发 RDB 快照...

ℹ 检查 RDB 文件...
  节点 7001: RDB 文件存在 (1.2K)
  节点 7002: RDB 文件存在 (1.3K)
  ...
✓ 发现 6 个 RDB 文件

ℹ 检查 AOF 文件...
  节点 7001: AOF 文件存在 ( 16K, 1 个文件)
  节点 7002: AOF 文件存在 ( 24K, 1 个文件)
  ...
✓ 发现 6 个 AOF 文件

✓ 数据完整性验证通过 (100/100)
```

---

### 5. 数据中心故障测试 (`datacenter-failure`) - P3

**测试目的**: 验证整个数据中心不可用时集群的表现

**测试流程**:
1. 写入 50 条测试数据
2. 停止一个主节点及其从节点（模拟数据中心故障）
3. 等待集群检测故障
4. 检查集群状态和读写能力
5. 恢复数据中心节点
6. 验证数据完整性

**预期结果**:
- 集群状态可能为 `ok` 或部分不可用（取决于槽位分布）
- 多数派节点仍可提供服务
- 数据完整性 100%

**示例输出**:
```
========================================
  数据中心故障测试 (P3)
========================================

ℹ 测试场景: 模拟整个数据中心不可用
ℹ 预期结果: 集群在剩余数据中心节点上继续服务

ℹ 当前主节点: 7004 7005 7006
✓ 已写入 50/50 条数据
ℹ 模拟数据中心故障: 停止主节点 7004 和从节点 7003

⚠ 停止数据中心节点...
✓ 节点 7004 已停止
✓ 节点 7003 已停止
ℹ 等待集群检测故障（约 10 秒）...
✓ 集群状态: ok（多数派节点正常）

ℹ 恢复数据中心节点...
✓ 节点 7004 已启动
✓ 节点 7003 已启动
✓ 数据完整性验证通过 (50/50)
```

---

### 6. 灾难恢复测试 (`disaster-recovery`) - P4

**测试目的**: 验证从备份恢复数据的完整流程

**测试流程**:
1. 写入 100 条测试数据
2. 触发 RDB 和 AOF 持久化
3. 创建数据备份
4. 模拟灾难：清空数据目录
5. 从备份恢复数据文件
6. 重启集群
7. 验证恢复的数据

**预期结果**:
- 备份成功创建
- 数据恢复成功率 ≥ 90%
- 集群重启后正常工作

**示例输出**:
```
========================================
  灾难恢复测试 (P4)
========================================

ℹ 测试场景: 模拟灾难后从备份恢复
ℹ 预期结果: 数据能够从 RDB/AOF 备份恢复

✓ 已写入 100/100 条数据
ℹ 记录测试数据...
ℹ 已写入 100 条数据
ℹ 触发持久化...
ℹ 创建备份到 /Users/kevin/.redis-cluster/backup_20260212_185344...
✓ 备份完成

⚠ 模拟灾难: 清空数据目录...
ℹ 从备份恢复数据...
✓ 数据恢复完成

ℹ 重启集群加载恢复的数据...
ℹ 验证恢复的数据...
✓ 数据恢复成功: 100/100 条数据已恢复
```

## 故障转移原理

### 故障检测

Redis Cluster 使用以下机制检测节点故障：

1. **心跳检测**: 每个节点定期向其他节点发送 PING 消息
2. **超时判断**: 如果节点在 `cluster-node-timeout`（默认 5 秒）内未响应，标记为 PFAIL（可能故障）
3. **多数确认**: 当大多数主节点认为某节点故障时，标记为 FAIL（确认故障）

### 故障转移流程

```
┌─────────────────────────────────────────────────────────────┐
│                      故障转移流程                            │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. 主节点故障                                               │
│     └──► 集群检测到主节点 FAIL                               │
│                                                              │
│  2. 从节点选举                                               │
│     └──► 从节点向其他主节点请求投票                          │
│     └──► 获得多数主节点投票的从节点胜出                      │
│                                                              │
│  3. 角色提升                                                 │
│     └──► 胜出的从节点提升为主节点                            │
│     └──► 接管原主节点的槽位                                  │
│                                                              │
│  4. 集群更新                                                 │
│     └──► 通知其他节点拓扑变更                                │
│     └──► 原主节点恢复后变为从节点                            │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 时间参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `cluster-node-timeout` | 5000ms | 节点故障判定超时时间 |
| 故障检测时间 | ~5-10s | 从节点故障到被标记为 FAIL |
| 故障转移时间 | ~1-2s | 从发起投票到完成提升 |
| 总恢复时间 | ~10-15s | 从故障到服务恢复 |

## 注意事项

### 测试前

1. **确保集群正常**: 运行 `./local-cluster.sh status` 检查集群状态
2. **备份数据**: 如有重要数据，请先备份
3. **预留时间**: 完整测试约需 1-2 分钟

### 测试中

1. **不要中断**: 测试过程中请勿手动操作集群
2. **观察日志**: 如遇问题，查看 `~/.redis-cluster/logs/` 下的日志文件

### 测试后

1. **检查状态**: 运行 `./local-cluster.sh status` 确认集群正常
2. **重启集群**: 如集群状态异常，运行 `./local-cluster.sh restart`

## 常见问题

### Q1: 节点启动失败

**原因**: macOS 安全机制导致日志文件权限问题

**解决方案**: 脚本已自动处理，重新生成配置文件并将日志输出到 `/dev/null`

### Q2: 数据完整性验证失败

**可能原因**:
- 故障转移尚未完成
- 网络延迟导致数据同步滞后

**解决方案**: 等待几秒后重新运行测试

### Q3: 故障转移未触发

**可能原因**:
- `cluster-node-timeout` 设置过长
- 从节点未正确配置

**解决方案**:
```bash
# 检查配置
redis-cli -p 7001 CONFIG GET cluster-node-timeout

# 检查从节点复制状态
redis-cli -p 7004 INFO replication
```

### Q4: AOF 文件未找到

**原因**: Redis 8.x 使用新的 AOF 目录结构

**位置**: `~/.redis-cluster/data/{port}/appendonlydir/`

## 手动故障转移

如需手动触发故障转移（例如维护时）：

```bash
# 在从节点上执行
redis-cli -p 7004 CLUSTER FAILOVER

# 强制故障转移（不等待主节点确认）
redis-cli -p 7004 CLUSTER FAILOVER FORCE

# 接管故障主节点
redis-cli -p 7004 CLUSTER FAILOVER TAKEOVER
```

## 相关命令

```bash
# 查看集群状态
./scripts/local-cluster.sh status

# 查看集群节点
./scripts/cluster-manager.sh nodes

# 健康检查
./scripts/monitor.sh health

# 重启集群
./scripts/local-cluster.sh restart
```

## 文件位置

| 文件 | 路径 |
|------|------|
| 测试脚本 | `scripts/failover-test.sh` |
| 集群管理 | `scripts/local-cluster.sh` |
| 集群监控 | `scripts/monitor.sh` |
| 日志文件 | `~/.redis-cluster/logs/` |
| 数据文件 | `~/.redis-cluster/data/` |
| 配置文件 | `~/.redis-cluster/conf/` |

---

**文档版本**: 1.0.0  
**最后更新**: 2026-02-12
