# Redis Cluster 双数据中心高可用架构设计文档

## 目录
1. [概述](#1-概述)
2. [架构设计](#2-架构设计)
3. [数据分片策略](#3-数据分片策略)
4. [高可用机制](#4-高可用机制)
5. [灾难恢复方案](#5-灾难恢复方案)
6. [配置示例](#6-配置示例)
7. [监控运维](#7-监控运维)
8. [部署指南](#8-部署指南)

---

## 1. 概述

### 1.1 项目背景
设计一套跨双数据中心的 Redis Cluster 高可用架构，确保在单数据中心故障时仍能提供服务，满足业务连续性要求。

### 1.2 设计目标
- **高可用性**：SLA ≥ 99.99%（年停机时间 < 53分钟）
- **数据一致性**：RPO（数据恢复点目标）≤ 1秒
- **快速恢复**：RTO（恢复时间目标）≤ 5分钟
- **容灾能力**：支持单数据中心完全故障

### 1.3 资源规划
| 数据中心 | 服务器数量 | 角色 |
|---------|-----------|------|
| DC-A（主数据中心） | 3台 | 3个主节点 |
| DC-B（备数据中心） | 3台 | 3个从节点 |
| **合计** | 6台 | 3主3从 |

---

## 2. 架构设计

### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Redis Cluster 架构                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────────────────── DC-A（主数据中心）──────────────────────┐ │
│  │                                                                         │ │
│  │  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                │ │
│  │  │   Node-1    │    │   Node-2    │    │   Node-3    │                │ │
│  │  │  Master     │    │  Master     │    │  Master     │                │ │
│  │  │  Slot:      │    │  Slot:      │    │  Slot:      │                │ │
│  │  │  0-5460     │    │  5461-10922 │    │  10923-16383│                │ │
│  │  │             │    │             │    │             │                │ │
│  │  │  Server:    │    │  Server:    │    │  Server:    │                │ │
│  │  │  10.1.1.1   │    │  10.1.1.2   │    │  10.1.1.3   │                │ │
│  │  │  Port: 6379 │    │  Port: 6379 │    │  Port: 6379 │                │ │
│  │  └──────┬──────┘    └──────┬──────┘    └──────┬──────┘                │ │
│  │         │                  │                  │                        │ │
│  │         │ 复制             │ 复制             │ 复制                   │ │
│  │         ▼                  ▼                  ▼                        │ │
│  │  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                │ │
│  │  │   Node-4    │    │   Node-5    │    │   Node-6    │                │ │
│  │  │  Slave      │    │  Slave      │    │  Slave      │                │ │
│  │  │  (DC-B)     │    │  (DC-B)     │    │  (DC-B)     │                │ │
│  │  │             │    │             │    │             │                │ │
│  │  │  Server:    │    │  Server:    │    │  Server:    │                │ │
│  │  │  10.2.1.1   │    │  10.2.1.2   │    │  10.2.1.3   │                │ │
│  │  │  Port: 6379 │    │  Port: 6379 │    │  Port: 6379 │                │ │
│  │  └─────────────┘    └─────────────┘    └─────────────┘                │ │
│  │                                                                         │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────── DC-B（备数据中心）──────────────────────┐ │
│  │                                                                         │ │
│  │  物理服务器：Server-4, Server-5, Server-6                               │ │
│  │  运行节点：Node-4(Slave), Node-5(Slave), Node-6(Slave)                 │ │
│  │                                                                         │ │
│  │  ★ 故障切换后可提升为主节点                                              │ │
│  │                                                                         │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  ┌─────────────────────────────── 客户端连接层 ───────────────────────────┐ │
│  │                                                                         │ │
│  │  ┌─────────────────────────────────────────────────────────────────┐  │ │
│  │  │  Redis Cluster 客户端 (Jedis / Lettuce / Redisson)              │  │ │
│  │  │                                                                  │  │ │
│  │  │  配置节点列表：                                                   │  │ │
│  │  │  ├── 10.1.1.1:6379 (Node-1, DC-A)                              │  │ │
│  │  │  ├── 10.1.1.2:6379 (Node-2, DC-A)                              │  │ │
│  │  │  ├── 10.1.1.3:6379 (Node-3, DC-A)                              │  │ │
│  │  │  ├── 10.2.1.1:6379 (Node-4, DC-B)                              │  │ │
│  │  │  ├── 10.2.1.2:6379 (Node-5, DC-B)                              │  │ │
│  │  │  └── 10.2.1.3:6379 (Node-6, DC-B)                              │  │ │
│  │  │                                                                  │  │ │
│  │  │  ★ 客户端自动发现集群拓扑、缓存槽位映射、智能路由                 │  │ │
│  │  └─────────────────────────────────────────────────────────────────┘  │ │
│  │                                                                         │ │
│  │  说明：Redis Cluster 模式下无需 VIP，客户端直接连接所有节点            │ │
│  │                                                                         │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 物理拓扑设计

#### 2.2.1 服务器分配

| 服务器编号 | 数据中心 | IP地址 | 部署节点 | 角色 |
|-----------|---------|--------|---------|------|
| Server-1 | DC-A | 10.1.1.1 | Node-1 | Master (Slot 0-5460) |
| Server-2 | DC-A | 10.1.1.2 | Node-2 | Master (Slot 5461-10922) |
| Server-3 | DC-A | 10.1.1.3 | Node-3 | Master (Slot 10923-16383) |
| Server-4 | DC-B | 10.2.1.1 | Node-4 | Slave of Node-1 |
| Server-5 | DC-B | 10.2.1.2 | Node-5 | Slave of Node-2 |
| Server-6 | DC-B | 10.2.1.3 | Node-6 | Slave of Node-3 |

#### 2.2.2 端口规划

| 端口 | 用途 |
|-----|------|
| 6379 | Redis 数据服务端口 |
| 16379 | Redis Cluster 总线端口（节点通信） |
| 26379 | Redis Sentinel 端口（可选） |

### 2.3 客户端连接架构

```
┌─────────────────────────────────────────────────────────────────┐
│                    客户端连接架构                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   应用层                                                          │
│   ┌──────────────────────────────────────────────────────────┐  │
│   │  客户端应用                                                │  │
│   │  └── Redis Cluster SDK (Jedis / Lettuce / Redisson)      │  │
│   │      ├── 配置所有节点地址                                 │  │
│   │      ├── 自动发现集群拓扑                                 │  │
│   │      ├── 本地缓存槽位映射表                               │  │
│   │      └── 智能路由 + 自动故障转移                          │  │
│   └──────────────────────────────────────────────────────────┘  │
│                           │                                      │
│         ┌─────────────────┼─────────────────┐                   │
│         ▼                 ▼                 ▼                   │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐            │
│   │   Node-1    │  │   Node-2    │  │   Node-3    │            │
│   │  Master     │  │  Master     │  │  Master     │            │
│   │  10.1.1.1   │  │  10.1.1.2   │  │  10.1.1.3   │            │
│   │  Slot:      │  │  Slot:      │  │  Slot:      │            │
│   │  0-5460     │  │  5461-10922 │  │  10923-16383│            │
│   └──────┬──────┘  └──────┬──────┘  └──────┬──────┘            │
│          │                │                │                    │
│          │    跨数据中心专线（低延迟 < 2ms）                     │
│          │                │                │                    │
│          ▼                ▼                ▼                    │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐            │
│   │   Node-4    │  │   Node-5    │  │   Node-6    │            │
│   │  Slave      │  │  Slave      │  │  Slave      │            │
│   │  10.2.1.1   │  │  10.2.1.2   │  │  10.2.1.3   │            │
│   └─────────────┘  └─────────────┘  └─────────────┘            │
│                                                                  │
│   ★ 说明：Redis Cluster 模式无需 VIP/负载均衡，客户端直连节点    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. 数据分片策略

### 3.1 槽位分配方案

Redis Cluster 共有 16384 个槽位（slot），分配给 3 个主节点：

| 节点 | 槽位范围 | 数量 | 数据中心 |
|-----|---------|------|---------|
| Node-1 | 0 ~ 5460 | 5461 | DC-A |
| Node-2 | 5461 ~ 10922 | 5462 | DC-A |
| Node-3 | 10923 ~ 16383 | 5461 | DC-A |

### 3.2 数据分布原理

```
┌─────────────────────────────────────────────────────────────────┐
│                    数据分片流程                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. Key 计算                                                     │
│     ┌──────────────────────────────────────────────────────┐   │
│     │  key: "user:1001"                                     │   │
│     │  CRC16(key) = 12345                                   │   │
│     │  slot = 12345 % 16384 = 12345                         │   │
│     └──────────────────────────────────────────────────────┘   │
│                                                                  │
│  2. 槽位定位                                                     │
│     ┌──────────────────────────────────────────────────────┐   │
│     │  Slot 12345 → Node-3 (10923-16383)                   │   │
│     └──────────────────────────────────────────────────────┘   │
│                                                                  │
│  3. 数据路由                                                     │
│     ┌──────────────────────────────────────────────────────┐   │
│     │  Client → Node-3 (Master)                            │   │
│     │         ↓ (异步复制)                                  │   │
│     │         Node-6 (Slave in DC-B)                       │   │
│     └──────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 3.3 Hash Tags 使用

为保证相关数据落在同一节点，使用 Hash Tags：

```
# 相关 Key 使用相同的 Hash Tag
user:{1001}:profile  → 同一槽位
user:{1001}:orders   → 同一槽位
user:{1001}:sessions → 同一槽位

# Hash Tag 计算
CRC16("{1001}") % 16384 = 固定槽位
```

---

## 4. 高可用机制

### 4.1 故障检测

```
┌─────────────────────────────────────────────────────────────────┐
│                    故障检测机制                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  配置参数：                                                      │
│  ├── cluster-node-timeout: 5000ms                               │
│  ├── cluster-slave-validity-factor: 10                         │
│  └── cluster-migration-barrier: 1                               │
│                                                                  │
│  检测流程：                                                      │
│                                                                  │
│  ┌─────────┐    PING/PONG     ┌─────────┐                      │
│  │ Node-1  │◄────────────────►│ Node-2  │                      │
│  └─────────┘                   └─────────┘                      │
│       │                                                             │
│       │ 超过 cluster-node-timeout 无响应                           │
│       ▼                                                             │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  1. 标记 Node-2 为 PFAIL (Possible Fail)               │    │
│  │  2. 多数节点确认后标记为 FAIL                           │    │
│  │  3. 触发故障转移                                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 故障转移流程

```
┌─────────────────────────────────────────────────────────────────┐
│                    故障转移流程                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  场景：Node-1 (Master in DC-A) 故障                              │
│                                                                  │
│  步骤 1: 故障检测                                                │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • 其他节点检测到 Node-1 无响应                          │  │
│  │  • 标记为 PFAIL                                          │  │
│  │  • 多数节点确认后标记为 FAIL                             │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  步骤 2: 选举投票                                                │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • Node-4 (Slave in DC-B) 发起选举请求                   │  │
│  │  • 向其他 Master 节点请求投票                            │  │
│  │  • 获得多数票后当选新 Master                             │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  步骤 3: 角色切换                                                │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • Node-4 提升为 Master                                 │  │
│  │  • 接管 Slot 0-5460                                     │  │
│  │  • 广播集群配置更新                                      │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  步骤 4: 客户端更新                                              │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • 客户端收到 MOVED 重定向                               │  │
│  │  • 更新本地槽位映射表                                    │  │
│  │  • 后续请求直接发送到新 Master                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  最终状态：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  DC-A: Node-2(M), Node-3(M), Node-1(故障)               │  │
│  │  DC-B: Node-4(M★), Node-5(S), Node-6(S)                 │  │
│  │                                                          │  │
│  │  ★ Node-4 已提升为 Master                               │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 4.3 仲裁机制

为确保跨数据中心场景下的正确仲裁，建议：

1. **外部配置管理**：使用配置中心管理集群配置
2. **仲裁节点**：可部署奇数个仲裁节点（如 3 个）
3. **网络分区处理**：配置合理的超时参数

```
┌─────────────────────────────────────────────────────────────────┐
│                    仲裁节点部署                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  方案一：使用 Redis Cluster 内置仲裁                             │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • 3 个 Master 节点构成仲裁组                            │  │
│  │  • 需要至少 2 个 Master 同意才能进行故障转移             │  │
│  │  • 简单但可能受网络分区影响                              │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  方案二：增加仲裁节点（推荐）                                     │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • 部署 3 个独立的仲裁节点                               │  │
│  │  │   ├── Arbiter-1 (DC-A)                               │  │
│  │  │   ├── Arbiter-2 (DC-B)                               │  │
│  │  │   └── Arbiter-3 (第三方位置/云上)                     │  │
│  │  • 参与投票但不存储数据                                  │  │
│  │  • 避免双主问题                                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 5. 灾难恢复方案

### 5.1 灾难场景分类

| 级别 | 场景 | 影响范围 | 恢复时间 |
|-----|------|---------|---------|
| P1 | 单节点故障 | 1个节点 | 自动恢复（秒级） |
| P2 | 单数据中心网络分区 | 1个数据中心 | 自动恢复（分钟级） |
| P3 | 单数据中心完全故障 | 整个数据中心 | 手动切换（分钟级） |
| P4 | 双数据中心同时故障 | 全部 | 从备份恢复（小时级） |

### 5.2 P1: 单节点故障恢复

```
┌─────────────────────────────────────────────────────────────────┐
│              P1: 单节点故障恢复流程                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  故障场景：Node-1 (Master) 硬件故障                              │
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  自动处理流程：                                          │  │
│  │                                                          │  │
│  │  1. [0-5s] 集群检测到 Node-1 故障                       │  │
│  │  2. [5-10s] Node-4 发起选举                             │  │
│  │  3. [10-15s] Node-4 当选新 Master                       │  │
│  │  4. [15-20s] 集群配置更新完成                           │  │
│  │                                                          │  │
│  │  恢复时间：约 15-20 秒                                   │  │
│  │  数据丢失：0（异步复制可能有 <1s 延迟）                  │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  后续处理：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  1. 修复或替换故障服务器                                 │  │
│  │  2. 将修复的 Node-1 配置为 Node-4 的从节点               │  │
│  │  3. 可选：手动切回原主数据中心                           │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 5.3 P2: 单数据中心网络分区恢复

```
┌─────────────────────────────────────────────────────────────────┐
│            P2: 单数据中心网络分区恢复流程                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  故障场景：DC-A 与 DC-B 之间网络中断                             │
│                                                                  │
│  初始状态：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  DC-A: Node-1(M), Node-2(M), Node-3(M)                  │  │
│  │  DC-B: Node-4(S), Node-5(S), Node-6(S)                  │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  网络分区后：                                                    │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  DC-A 分区（拥有多数 Master）：                          │  │
│  │  • 继续正常服务                                          │  │
│  │  • 3 个 Master 构成仲裁多数                              │  │
│  │                                                          │  │
│  │  DC-B 分区（少数派）：                                   │  │
│  │  • Slave 无法获得足够票数成为 Master                     │  │
│  │  • 等待网络恢复                                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  网络恢复后：                                                    │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  1. DC-B 节点重新连接到集群                             │  │
│  │  2. 自动同步网络分区期间的数据                           │  │
│  │  3. 恢复正常的主从复制关系                               │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  ★ 关键配置：cluster-node-timeout 设置需考虑网络延迟           │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 5.4 P3: 单数据中心完全故障恢复

```
┌─────────────────────────────────────────────────────────────────┐
│          P3: 单数据中心完全故障恢复流程                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  故障场景：DC-A 完全不可用（断电、火灾等）                        │
│                                                                  │
│  初始状态：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  DC-A: Node-1(M), Node-2(M), Node-3(M) [全部故障]       │  │
│  │  DC-B: Node-4(S), Node-5(S), Node-6(S) [正常]           │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  自动恢复流程（需配置外部仲裁）：                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  方案 A: 使用外部仲裁节点                                │  │
│  │  1. 外部仲裁节点检测到 DC-A 故障                        │  │
│  │  2. 与 DC-B 节点组成新的仲裁多数                        │  │
│  │  3. DC-B 的 Slave 节点自动提升为 Master                 │  │
│  │  4. 恢复时间：1-2 分钟                                   │  │
│  │                                                          │  │
│  │  方案 B: 手动故障转移                                    │  │
│  │  1. 运维人员确认 DC-A 故障                              │  │
│  │  2. 在 DC-B 执行集群重建命令                            │  │
│  │  3. 将 Node-4,5,6 提升为 Master                        │  │
│  │  4. 更新应用层连接配置                                   │  │
│  │  5. 恢复时间：5-10 分钟                                  │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  手动故障转移命令：                                              │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  # 在 DC-B 的任一节点执行                               │  │
│  │  redis-cli --cluster failover 10.2.1.1:6379             │  │
│  │  redis-cli --cluster failover 10.2.1.2:6379             │  │
│  │  redis-cli --cluster failover 10.2.1.3:6379             │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  DC-A 恢复后：                                                   │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  1. DC-A 服务器恢复                                      │  │
│  │  2. 将原 Master 节点配置为 DC-B 的 Slave                │  │
│  │  3. 数据同步完成后，可选择切回 DC-A                     │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 5.5 P4: 双数据中心故障恢复

```
┌─────────────────────────────────────────────────────────────────┐
│          P4: 双数据中心故障恢复流程                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  故障场景：双数据中心同时故障（极端情况）                         │
│                                                                  │
│  恢复流程：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  1. 评估故障原因和影响范围                               │  │
│  │  2. 恢复基础设施（电力、网络）                           │  │
│  │  3. 选择恢复顺序：                                       │  │
│  │     ├── 优先恢复主数据中心 DC-A                         │  │
│  │     └── 或优先恢复条件较好的数据中心                    │  │
│  │  4. 启动 Redis 节点                                      │  │
│  │  5. 检查数据完整性                                       │  │
│  │  6. 恢复应用服务                                         │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  数据恢复方案：                                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  方案 A: 从 RDB/AOF 备份恢复                             │  │
│  │  ├── 停止所有 Redis 节点                                │  │
│  │  ├── 恢复最新的 RDB/AOF 文件                            │  │
│  │  ├── 启动节点并验证数据                                 │  │
│  │  └── 重建集群关系                                       │  │
│  │                                                          │  │
│  │  方案 B: 从异地备份恢复                                  │  │
│  │  ├── 获取异地备份中心的最新备份                         │  │
│  │  ├── 恢复到任一数据中心                                 │  │
│  │  └── 重建集群并同步到另一数据中心                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  数据丢失评估：                                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  RPO: 取决于最后一次备份时间                            │  │
│  │  ├── 定时备份（每小时）：最大丢失 1 小时数据            │  │
│  │  ├── 实时备份（AOF）：最大丢失 1 秒数据                 │  │
│  │  └── 建议配置 AOF + 定时 RDB 双重保障                   │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 5.6 灾备演练计划

```
┌─────────────────────────────────────────────────────────────────┐
│                    灾备演练计划                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  演练频率：每季度一次                                            │
│                                                                  │
│  演练场景：                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  Q1: 单节点故障自动转移演练                              │  │
│  │  ├── 模拟 Master 节点宕机                               │  │
│  │  ├── 验证自动故障转移                                   │  │
│  │  └── 验证客户端重连                                     │  │
│  │                                                          │  │
│  │  Q2: 单数据中心故障演练                                  │  │
│  │  ├── 模拟 DC-A 完全不可用                               │  │
│  │  ├── 执行手动故障转移                                   │  │
│  │  └── 验证 DC-B 接管服务                                 │  │
│  │                                                          │  │
│  │  Q3: 数据恢复演练                                        │  │
│  │  ├── 模拟数据丢失场景                                   │  │
│  │  ├── 从备份恢复数据                                     │  │
│  │  └── 验证数据完整性                                     │  │
│  │                                                          │  │
│  │  Q4: 全流程综合演练                                      │  │
│  │  ├── 模拟多种故障组合                                   │  │
│  │  ├── 验证监控告警                                       │  │
│  │  └── 验证人员响应流程                                   │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  演练检查清单：                                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  □ 演练前通知相关人员                                   │  │
│  │  □ 准备回滚方案                                         │  │
│  │  □ 记录演练过程和问题                                   │  │
│  │  □ 演练后总结和改进                                     │  │
│  │  □ 更新灾备文档                                         │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 6. 配置示例

### 6.1 Redis Cluster 节点配置

#### Node-1 (Master in DC-A) - /etc/redis/redis-6379.conf

```conf
# ==================== 基础配置 ====================
bind 0.0.0.0
port 6379
daemonize yes
pidfile /var/run/redis/redis-6379.pid
logfile /var/log/redis/redis-6379.log
dir /data/redis/6379

# ==================== 集群配置 ====================
cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 5000
cluster-slave-validity-factor 10
cluster-migration-barrier 1
cluster-require-full-coverage no

# ==================== 复制配置 ====================
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync yes
repl-diskless-sync-delay 5
repl-timeout 60

# ==================== 持久化配置 ====================
# RDB 快照
save 900 1
save 300 10
save 60 10000
dbfilename dump-6379.rdb

# AOF 持久化
appendonly yes
appendfilename "appendonly-6379.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# ==================== 内存管理 ====================
maxmemory 8gb
maxmemory-policy allkeys-lru

# ==================== 性能优化 ====================
tcp-backlog 511
tcp-keepalive 300
timeout 0
slowlog-log-slower-than 10000
slowlog-max-len 128

# ==================== 安全配置 ====================
requirepass YourStrongPassword123!
masterauth YourStrongPassword123!

# ==================== 监控配置 ====================
latency-monitor-threshold 100
latency-tracking yes
```

#### Node-4 (Slave in DC-B) - /etc/redis/redis-6379.conf

```conf
# ==================== 基础配置 ====================
bind 0.0.0.0
port 6379
daemonize yes
pidfile /var/run/redis/redis-6379.pid
logfile /var/log/redis/redis-6379.log
dir /data/redis/6379

# ==================== 集群配置 ====================
cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 5000
cluster-slave-validity-factor 10
cluster-migration-barrier 1
cluster-require-full-coverage no

# ==================== 复制配置 ====================
# 指定主节点（集群创建后自动配置，此处为示例）
# replicaof 10.1.1.1 6379
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync yes
repl-diskless-sync-delay 5
repl-timeout 60

# ==================== 持久化配置 ====================
save 900 1
save 300 10
save 60 10000
dbfilename dump-6379.rdb

appendonly yes
appendfilename "appendonly-6379.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# ==================== 内存管理 ====================
maxmemory 8gb
maxmemory-policy allkeys-lru

# ==================== 性能优化 ====================
tcp-backlog 511
tcp-keepalive 300
timeout 0
slowlog-log-slower-than 10000
slowlog-max-len 128

# ==================== 安全配置 ====================
requirepass YourStrongPassword123!
masterauth YourStrongPassword123!

# ==================== 监控配置 ====================
latency-monitor-threshold 100
latency-tracking yes
```

### 6.2 集群创建脚本

```bash
#!/bin/bash
# ====================
# Redis Cluster 创建脚本
# ====================

# 节点列表
NODES=(
    "10.1.1.1:6379"
    "10.1.1.2:6379"
    "10.1.1.3:6379"
    "10.2.1.1:6379"
    "10.2.1.2:6379"
    "10.2.1.3:6379"
)

# 密码
REDIS_PASSWORD="YourStrongPassword123!"

# 创建集群（3主3从）
echo "Creating Redis Cluster..."
redis-cli --cluster create \
    10.1.1.1:6379 \
    10.1.1.2:6379 \
    10.1.1.3:6379 \
    10.2.1.1:6379 \
    10.2.1.2:6379 \
    10.2.1.3:6379 \
    --cluster-replicas 1 \
    -a $REDIS_PASSWORD

echo "Cluster created successfully!"

# 验证集群状态
echo "Checking cluster status..."
redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster info
redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster nodes
```

### 6.3 主从关系调整脚本

```bash
#!/bin/bash
# ====================
# 调整主从关系，确保跨数据中心复制
# ====================

REDIS_PASSWORD="YourStrongPassword123!"

# 获取节点 ID
NODE1_ID=$(redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster myid)
NODE2_ID=$(redis-cli -h 10.1.1.2 -p 6379 -a $REDIS_PASSWORD cluster myid)
NODE3_ID=$(redis-cli -h 10.1.1.3 -p 6379 -a $REDIS_PASSWORD cluster myid)

echo "Node IDs:"
echo "Node-1: $NODE1_ID"
echo "Node-2: $NODE2_ID"
echo "Node-3: $NODE3_ID"

# 将 DC-B 的节点配置为 DC-A 节点的从节点
echo "Configuring replication across datacenters..."

# Node-4 复制 Node-1
redis-cli -h 10.2.1.1 -p 6379 -a $REDIS_PASSWORD cluster replicate $NODE1_ID

# Node-5 复制 Node-2
redis-cli -h 10.2.1.2 -p 6379 -a $REDIS_PASSWORD cluster replicate $NODE2_ID

# Node-6 复制 Node-3
redis-cli -h 10.2.1.3 -p 6379 -a $REDIS_PASSWORD cluster replicate $NODE3_ID

echo "Replication configured successfully!"

# 验证主从关系
echo "Verifying replication..."
redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster nodes
```

### 6.4 客户端连接配置

#### 6.4.1 Spring Boot 配置（推荐）

```yaml
# application.yml
spring:
  redis:
    cluster:
      nodes:
        - 10.1.1.1:6379
        - 10.1.1.2:6379
        - 10.1.1.3:6379
        - 10.2.1.1:6379
        - 10.2.1.2:6379
        - 10.2.1.3:6379
      max-redirects: 3
    password: YourStrongPassword123!
    lettuce:
      pool:
        max-active: 16
        max-idle: 8
        min-idle: 2
        max-wait: 3000ms
      shutdown-timeout: 200ms
    timeout: 3000ms
```

#### 6.4.2 Jedis 客户端配置

```java
import redis.clients.jedis.JedisCluster;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.JedisPoolConfig;
import java.util.HashSet;
import java.util.Set;

/**
 * Jedis Cluster 客户端配置
 */
public class JedisClusterConfig {
    
    public JedisCluster jedisCluster() {
        Set<HostAndPort> nodes = new HashSet<>();
        nodes.add(new HostAndPort("10.1.1.1", 6379));
        nodes.add(new HostAndPort("10.1.1.2", 6379));
        nodes.add(new HostAndPort("10.1.1.3", 6379));
        nodes.add(new HostAndPort("10.2.1.1", 6379));
        nodes.add(new HostAndPort("10.2.1.2", 6379));
        nodes.add(new HostAndPort("10.2.1.3", 6379));
        
        JedisPoolConfig poolConfig = new JedisPoolConfig();
        poolConfig.setMaxTotal(16);
        poolConfig.setMaxIdle(8);
        poolConfig.setMinIdle(2);
        poolConfig.setMaxWaitMillis(3000);
        
        return new JedisCluster(
            nodes,
            3000,
            3000,
            3,
            "YourStrongPassword123!",
            poolConfig
        );
    }
}
```

#### 6.4.3 Lettuce 客户端配置

```java
import io.lettuce.core.RedisURI;
import io.lettuce.core.cluster.RedisClusterClient;
import io.lettuce.core.cluster.api.StatefulRedisClusterConnection;
import io.lettuce.core.resource.ClientResources;
import io.lettuce.core.resource.DefaultClientResources;
import java.util.Arrays;
import java.util.List;

/**
 * Lettuce Cluster 客户端配置
 */
public class LettuceClusterConfig {
    
    public RedisClusterClient redisClusterClient() {
        List<RedisURI> nodes = Arrays.asList(
            RedisURI.create("10.1.1.1", 6379),
            RedisURI.create("10.1.1.2", 6379),
            RedisURI.create("10.1.1.3", 6379),
            RedisURI.create("10.2.1.1", 6379),
            RedisURI.create("10.2.1.2", 6379),
            RedisURI.create("10.2.1.3", 6379)
        );
        
        nodes.forEach(uri -> {
            uri.setPassword("YourStrongPassword123!");
            uri.setTimeout(java.time.Duration.ofSeconds(3));
        });
        
        ClientResources resources = DefaultClientResources.builder()
            .ioThreadPoolSize(4)
            .computationThreadPoolSize(4)
            .build();
        
        return RedisClusterClient.create(resources, nodes);
    }
}
```

#### 6.4.4 Redisson 客户端配置

```java
import org.redisson.Redisson;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;

/**
 * Redisson Cluster 客户端配置
 */
public class RedissonClusterConfig {
    
    public RedissonClient redissonClient() {
        Config config = new Config();
        config.useClusterServers()
            .addNodeAddress(
                "redis://10.1.1.1:6379",
                "redis://10.1.1.2:6379",
                "redis://10.1.1.3:6379",
                "redis://10.2.1.1:6379",
                "redis://10.2.1.2:6379",
                "redis://10.2.1.3:6379"
            )
            .setPassword("YourStrongPassword123!")
            .setConnectTimeout(3000)
            .setTimeout(3000)
            .setRetryAttempts(3)
            .setRetryInterval(1500)
            .setMasterConnectionPoolSize(16)
            .setSlaveConnectionPoolSize(16);
        
        return Redisson.create(config);
    }
}
```

#### 6.4.5 客户端连接说明

```
┌─────────────────────────────────────────────────────────────────┐
│                  客户端连接关键说明                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. 节点配置数量                                                 │
│     ├── 建议配置所有节点（6个）                                  │
│     ├── 最少配置 2-3 个节点即可自动发现                          │
│     └── 配置越多，初始连接成功率越高                             │
│                                                                  │
│  2. 无需 VIP/负载均衡                                            │
│     ├── Redis Cluster 客户端直接连接节点                         │
│     ├── 客户端自动发现集群拓扑                                   │
│     └── 客户端本地缓存槽位映射表                                 │
│                                                                  │
│  3. 故障转移处理                                                 │
│     ├── 客户端自动处理 MOVED 重定向                              │
│     ├── 客户端自动更新槽位映射                                   │
│     └── 无需人工干预                                             │
│                                                                  │
│  4. 跨数据中心注意事项                                           │
│     ├── 确保客户端能访问两个数据中心的节点                       │
│     ├── 配置合理的超时时间（建议 3-5 秒）                        │
│     └── 配置重试次数（建议 3 次）                                │
│                                                                  │
│  5. 连接池配置建议                                               │
│     ├── max-active: 根据并发量设置（建议 16-32）                 │
│     ├── max-idle: 建议 max-active 的一半                        │
│     ├── min-idle: 保持少量空闲连接（建议 2-4）                   │
│     └── max-wait: 获取连接超时（建议 3000ms）                    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 7. 监控运维

### 7.1 监控指标

```
┌─────────────────────────────────────────────────────────────────┐
│                    关键监控指标                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  集群状态指标                                                    │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • cluster_state: ok/fail                                │  │
│  │  • cluster_slots_assigned: 16384                         │  │
│  │  • cluster_slots_ok: 16384                               │  │
│  │  • cluster_slots_pfail: 0                                │  │
│  │  • cluster_slots_fail: 0                                 │  │
│  │  • cluster_known_nodes: 6                                │  │
│  │  • cluster_size: 3                                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  节点状态指标                                                    │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • connected_clients: 客户端连接数                       │  │
│  │  • blocked_clients: 阻塞客户端数                         │  │
│  │  • used_memory: 已使用内存                               │  │
│  │  • used_memory_peak: 内存使用峰值                        │  │
│  │  • mem_fragmentation_ratio: 内存碎片率                   │  │
│  │  • total_commands_processed: 总命令数                    │  │
│  │  • instantaneous_ops_per_sec: 当前 QPS                   │  │
│  │  • total_net_input_bytes: 网络输入字节                   │  │
│  │  • total_net_output_bytes: 网络输出字节                  │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  复制状态指标                                                    │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • master_link_status: up/down                           │  │
│  │  • master_sync_in_progress: 同步进行中                   │  │
│  │  • master_repl_offset: 主节点复制偏移量                  │  │
│  │  • slave_repl_offset: 从节点复制偏移量                   │  │
│  │  • repl_backlog_size: 复制积压缓冲区大小                 │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  持久化指标                                                      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  • rdb_last_save_time: 最后一次 RDB 保存时间             │  │
│  │  • rdb_changes_since_last_save: 距离上次保存的变更数     │  │
│  │  • aof_enabled: AOF 是否启用                             │  │
│  │  • aof_rewrite_in_progress: AOF 重写进行中               │  │
│  │  • aof_last_rewrite_time_sec: 最后一次 AOF 重写耗时      │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 7.2 Prometheus 监控配置

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'redis-cluster'
    static_configs:
      - targets:
          - '10.1.1.1:9121'
          - '10.1.1.2:9121'
          - '10.1.1.3:9121'
          - '10.2.1.1:9121'
          - '10.2.1.2:9121'
          - '10.2.1.3:9121'
        labels:
          environment: 'production'
```

### 7.3 告警规则

```yaml
# redis-alerts.yml
groups:
  - name: redis-cluster
    rules:
      - alert: RedisClusterDown
        expr: redis_cluster_state != 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis Cluster 状态异常"
          description: "Redis Cluster 状态为 fail，请立即检查"

      - alert: RedisNodeDown
        expr: redis_up == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Redis 节点不可用"
          description: "Redis 节点 {{ $labels.instance }} 已宕机"

      - alert: RedisReplicationBroken
        expr: redis_replication_link_status == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis 主从复制中断"
          description: "节点 {{ $labels.instance }} 主从复制已断开"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis 内存使用率过高"
          description: "节点 {{ $labels.instance }} 内存使用率超过 80%"

      - alert: RedisReplicationLag
        expr: redis_replication_lag_seconds > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Redis 主从复制延迟过高"
          description: "节点 {{ $labels.instance }} 复制延迟超过 10 秒"
```

### 7.4 日常运维脚本

```bash
#!/bin/bash
# ====================
# Redis Cluster 健康检查脚本
# ====================

REDIS_PASSWORD="YourStrongPassword123!"
ALERT_WEBHOOK="https://your-webhook-url"

check_cluster_health() {
    echo "=== Redis Cluster Health Check ==="
    echo "Time: $(date)"
    echo ""
    
    # 检查集群状态
    CLUSTER_STATE=$(redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster info | grep cluster_state | cut -d: -f2 | tr -d '\r')
    
    if [ "$CLUSTER_STATE" != "ok" ]; then
        echo "[CRITICAL] Cluster state: $CLUSTER_STATE"
        send_alert "Redis Cluster 状态异常: $CLUSTER_STATE"
    else
        echo "[OK] Cluster state: $CLUSTER_STATE"
    fi
    
    # 检查各节点状态
    echo ""
    echo "=== Node Status ==="
    redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster nodes | while read line; do
        NODE_ID=$(echo $line | awk '{print $1}')
        NODE_ADDR=$(echo $line | awk '{print $2}')
        NODE_FLAGS=$(echo $line | awk '{print $3}')
        NODE_MASTER=$(echo $line | awk '{print $4}')
        NODE_PING=$(echo $line | awk '{print $5}')
        NODE_PONG=$(echo $line | awk '{print $6}')
        NODE_EPOCH=$(echo $line | awk '{print $7}')
        NODE_STATE=$(echo $line | awk '{print $8}')
        
        echo "Node: $NODE_ADDR"
        echo "  Flags: $NODE_FLAGS"
        echo "  State: $NODE_STATE"
        
        if [[ "$NODE_FLAGS" == *"fail"* ]]; then
            echo "  [WARNING] Node is in fail state"
            send_alert "Redis 节点异常: $NODE_ADDR 状态: $NODE_FLAGS"
        fi
        echo ""
    done
    
    # 检查内存使用
    echo "=== Memory Usage ==="
    for node in 10.1.1.1 10.1.1.2 10.1.1.3 10.2.1.1 10.2.1.2 10.2.1.3; do
        MEM_USED=$(redis-cli -h $node -p 6379 -a $REDIS_PASSWORD info memory | grep used_memory_human | cut -d: -f2 | tr -d '\r')
        MEM_MAX=$(redis-cli -h $node -p 6379 -a $REDIS_PASSWORD info memory | grep maxmemory_human | cut -d: -f2 | tr -d '\r')
        echo "$node: Used=$MEM_USED, Max=$MEM_MAX"
    done
    
    # 检查复制延迟
    echo ""
    echo "=== Replication Lag ==="
    for node in 10.2.1.1 10.2.1.2 10.2.1.3; do
        LAG=$(redis-cli -h $node -p 6379 -a $REDIS_PASSWORD info replication | grep master_link_status | cut -d: -f2 | tr -d '\r')
        OFFSET=$(redis-cli -h $node -p 6379 -a $REDIS_PASSWORD info replication | grep slave_repl_offset | cut -d: -f2 | tr -d '\r')
        echo "$node: Link=$LAG, Offset=$OFFSET"
    done
}

send_alert() {
    MESSAGE=$1
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"$MESSAGE\"}" \
        $ALERT_WEBHOOK
}

# 执行检查
check_cluster_health
```

### 7.5 备份策略

```bash
#!/bin/bash
# ====================
# Redis Cluster 备份脚本
# ====================

BACKUP_DIR="/data/redis/backup"
DATE=$(date +%Y%m%d_%H%M%S)
REDIS_PASSWORD="YourStrongPassword123!"

# 创建备份目录
mkdir -p $BACKUP_DIR/$DATE

# 备份所有节点的 RDB 和 AOF
for node in 10.1.1.1 10.1.1.2 10.1.1.3 10.2.1.1 10.2.1.2 10.2.1.3; do
    echo "Backing up $node..."
    
    # 触发 RDB 快照
    redis-cli -h $node -p 6379 -a $REDIS_PASSWORD BGSAVE
    
    # 等待快照完成
    sleep 5
    
    # 复制备份文件
    scp redis@$node:/data/redis/6379/dump-6379.rdb $BACKUP_DIR/$DATE/${node}_dump.rdb
    scp redis@$node:/data/redis/6379/appendonly-6379.aof $BACKUP_DIR/$DATE/${node}_appendonly.aof
done

# 备份集群配置
redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster nodes > $BACKUP_DIR/$DATE/cluster_nodes.txt
redis-cli -h 10.1.1.1 -p 6379 -a $REDIS_PASSWORD cluster info > $BACKUP_DIR/$DATE/cluster_info.txt

# 压缩备份
cd $BACKUP_DIR
tar -czf redis_backup_$DATE.tar.gz $DATE
rm -rf $DATE

# 删除 7 天前的备份
find $BACKUP_DIR -name "redis_backup_*.tar.gz" -mtime +7 -delete

echo "Backup completed: redis_backup_$DATE.tar.gz"
```

---

## 8. 部署指南

### 8.1 部署前准备

```
┌─────────────────────────────────────────────────────────────────┐
│                    部署检查清单                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  硬件要求                                                        │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  □ CPU: 8 核以上                                         │  │
│  │  □ 内存: 16GB 以上（Redis 使用 8GB）                     │  │
│  │  □ 磁盘: SSD 100GB 以上                                  │  │
│  │  □ 网络: 万兆网卡                                        │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  网络要求                                                        │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  □ 数据中心内网络延迟 < 1ms                               │  │
│  │  □ 跨数据中心网络延迟 < 2ms                               │  │
│  │  □ 端口开放: 6379, 16379                                 │  │
│  │  □ 跨数据中心专线带宽充足                                │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
│  系统要求                                                        │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  □ 操作系统: Linux (CentOS 7+/Ubuntu 18.04+)             │  │
│  │  □ Redis 版本: 6.2+ 或 7.0+                              │  │
│  │  □ 系统参数优化:                                         │  │
│  │    - vm.overcommit_memory = 1                            │  │
│  │    - net.core.somaxconn = 65535                          │  │
│  │    - net.ipv4.tcp_max_syn_backlog = 65535                │  │
│  │    - transparent_hugepage disabled                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 8.2 系统参数优化

```bash
# /etc/sysctl.conf
# Redis 优化参数

# 内存分配策略
vm.overcommit_memory = 1

# 网络连接队列
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_syncookies = 1

# TCP 连接复用
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30

# 文件描述符限制
fs.file-max = 1000000

# 应用配置
sysctl -p
```

```bash
# /etc/security/limits.conf
# Redis 用户资源限制

redis soft nofile 65535
redis hard nofile 65535
redis soft nproc 65535
redis hard nproc 65535
```

### 8.3 部署步骤

```bash
# ====================
# 步骤 1: 安装 Redis
# ====================

# 在所有节点执行
yum install -y redis

# 或编译安装
wget https://download.redis.io/redis-stable.tar.gz
tar xzf redis-stable.tar.gz
cd redis-stable
make
make install

# ====================
# 步骤 2: 创建必要目录
# ====================

mkdir -p /data/redis/6379
mkdir -p /var/log/redis
mkdir -p /var/run/redis
chown -R redis:redis /data/redis
chown -R redis:redis /var/log/redis
chown -R redis:redis /var/run/redis

# ====================
# 步骤 3: 部署配置文件
# ====================

# 复制配置文件到各节点
# 参考 6.1 节的配置示例

# ====================
# 步骤 4: 启动 Redis 节点
# ====================

# 在所有节点启动
systemctl start redis
# 或
redis-server /etc/redis/redis-6379.conf

# ====================
# 步骤 5: 创建集群
# ====================

# 在任一节点执行
redis-cli --cluster create \
    10.1.1.1:6379 \
    10.1.1.2:6379 \
    10.1.1.3:6379 \
    10.2.1.1:6379 \
    10.2.1.2:6379 \
    10.2.1.3:6379 \
    --cluster-replicas 1 \
    -a YourStrongPassword123!

# ====================
# 步骤 6: 调整主从关系
# ====================

# 参考 6.3 节的脚本

# ====================
# 步骤 7: 验证集群
# ====================

# 检查集群状态
redis-cli -h 10.1.1.1 -p 6379 -a YourStrongPassword123! cluster info

# 检查节点状态
redis-cli -h 10.1.1.1 -p 6379 -a YourStrongPassword123! cluster nodes

# 测试数据读写
redis-cli -h 10.1.1.1 -p 6379 -a YourStrongPassword123! set test_key "Hello Redis Cluster"
redis-cli -h 10.1.1.1 -p 6379 -a YourStrongPassword123! get test_key
```

### 8.4 客户端连接配置

#### Java (Jedis)

```java
import redis.clients.jedis.*;

/**
 * Redis Cluster 客户端配置类
 */
public class RedisClusterConfig {
    
    /**
     * 创建 Redis Cluster 连接池
     * 
     * @return JedisCluster 实例
     */
    public static JedisCluster createCluster() {
        Set<HostAndPort> nodes = new HashSet<>();
        nodes.add(new HostAndPort("10.1.1.1", 6379));
        nodes.add(new HostAndPort("10.1.1.2", 6379));
        nodes.add(new HostAndPort("10.1.1.3", 6379));
        nodes.add(new HostAndPort("10.2.1.1", 6379));
        nodes.add(new HostAndPort("10.2.1.2", 6379));
        nodes.add(new HostAndPort("10.2.1.3", 6379));
        
        JedisPoolConfig poolConfig = new JedisPoolConfig();
        poolConfig.setMaxTotal(200);
        poolConfig.setMaxIdle(50);
        poolConfig.setMinIdle(10);
        poolConfig.setMaxWaitMillis(3000);
        poolConfig.setTestOnBorrow(true);
        poolConfig.setTestOnReturn(true);
        poolConfig.setTestWhileIdle(true);
        
        return new JedisCluster(
            nodes,
            5000,    // connection timeout
            5000,    // read timeout
            5,       // max attempts
            "YourStrongPassword123!",
            poolConfig
        );
    }
}
```

#### Python (redis-py)

```python
from redis.cluster import RedisCluster
from redis.cluster import ClusterNode

def create_redis_cluster():
    """
    创建 Redis Cluster 客户端连接
    
    Returns:
        RedisCluster: Redis Cluster 客户端实例
    """
    nodes = [
        ClusterNode('10.1.1.1', 6379),
        ClusterNode('10.1.1.2', 6379),
        ClusterNode('10.1.1.3', 6379),
        ClusterNode('10.2.1.1', 6379),
        ClusterNode('10.2.1.2', 6379),
        ClusterNode('10.2.1.3', 6379),
    ]
    
    return RedisCluster(
        startup_nodes=nodes,
        password='YourStrongPassword123!',
        max_connections=200,
        socket_timeout=5,
        socket_connect_timeout=5,
        retry_on_timeout=True,
        max_attempts=3
    )
```

---

## 附录

### A. 常用命令速查

```bash
# 集群信息
redis-cli -h <host> -p 6379 -a <password> cluster info
redis-cli -h <host> -p 6379 -a <password> cluster nodes

# 节点信息
redis-cli -h <host> -p 6379 -a <password> info
redis-cli -h <host> -p 6379 -a <password> info replication
redis-cli -h <host> -p 6379 -a <password> info memory

# 故障转移
redis-cli -h <slave_host> -p 6379 -a <password> cluster failover

# 添加节点
redis-cli --cluster add-node <new_node>:6379 <existing_node>:6379

# 删除节点
redis-cli --cluster del-node <node>:6379 <node_id>

# 重新分片
redis-cli --cluster reshard <host>:6379

# 检查集群
redis-cli --cluster check <host>:6379

# 修复集群
redis-cli --cluster fix <host>:6379
```

### B. 故障排查指南

| 问题 | 可能原因 | 解决方案 |
|-----|---------|---------|
| 节点无法加入集群 | 网络不通/端口未开放 | 检查网络和防火墙 |
| 主从复制中断 | 网络延迟/主节点压力 | 检查网络/优化主节点 |
| 集群状态为 fail | 槽位未完全覆盖 | 使用 cluster fix 修复 |
| 内存不足 | 数据量过大 | 扩容或清理数据 |
| 客户端连接失败 | 认证失败/节点宕机 | 检查密码和节点状态 |

---

**文档版本**: v1.0  
**创建日期**: 2026-02-12  
**最后更新**: 2026-02-12
